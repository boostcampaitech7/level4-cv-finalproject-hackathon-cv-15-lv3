import pandas as pd
import torch
from faiss_search import FaissSearch, DeepLTranslator
from transformers import AutoModelForSequenceClassification, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-base')
model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-base')

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
query_path = "/data/ephemeral/home/level4-cv-finalproject-hackathon-cv-15-lv3/json/gt_5.json"
db_path = "/data/ephemeral/home/level4-cv-finalproject-hackathon-cv-15-lv3/json/caption_embedding_tf_mpnet.json"

# Excel íŒŒì¼ ì½ê¸°
df = pd.read_json(query_path)

# FAISS ê²€ìƒ‰ ì´ˆê¸°í™”
translator = DeepLTranslator()
faiss_search = FaissSearch(json_path=db_path, use_gpu=True, model_name="all-mpnet-base-v2")  # CPU ì‚¬ìš©

# í‰ê°€ ì§€í‘œ ì´ˆê¸°í™”
metrics = {
    'total_queries': len(df),
    'found_in_topk': 0,
    'mean_rank': 0,
    'mean_similarity': 0,
    'detailed_results': []
}
top_k = 15
print(f"\nğŸ“Š ê²€ìƒ‰ ì„±ëŠ¥ í‰ê°€ ì‹œì‘ (top-{top_k})")

df = df.iloc[:6]

for _, row in df.iterrows():
    query = row['query']
    video_id = row['video_id']
    gt_start = row['start_time']
    gt_end = row['end_time']
    
    # ì¿¼ë¦¬ ë²ˆì—­
    query_en = translator.translate_ko_to_en(query)
    print(f"\nğŸ” ì¿¼ë¦¬ í‰ê°€ ì¤‘:")
    print(f"   ì›ë³¸: {query}")
    print(f"   ë²ˆì—­: {query_en}")
    
    # ì „ì²´ DBì—ì„œ ê²€ìƒ‰
    results = faiss_search.find_similar_captions(query_en, top_k=top_k)
    
    # ê²°ê³¼ ë¶„ì„
    found = False
    rank = -1
    max_similarity = 0
    
    en_caption_query = []
    
    for i, (caption_en, caption_ko, similarity, video_info) in enumerate(results, 1):
        en_caption_query.append([query_en, caption_en])

    with torch.no_grad():
        inputs = tokenizer(en_caption_query, padding=True, truncation=True, return_tensors='pt', max_length=512)
        scores = model(**inputs, return_dict=True).logits.view(-1, ).float()
        # print(scores)
    
    for i in range(len(results)):
        print(results[i][2], scores[i])
        results[i] = list(results[i])
        results[i][2] = scores[i]
        
    results.sort(key=lambda x: x[2], reverse=True)
    
    for i, (caption_en, caption_ko, similarity, video_info) in enumerate(results, 1):
        # video_pathì—ì„œ video_id ì¶”ì¶œ
        result_video_id = video_info.get('video_id')
        start_time = float(video_info['start_time'])
        end_time = float(video_info['end_time'])

        gt_start = gt_start.timestamp() if isinstance(gt_start, pd.Timestamp) else float(gt_start)
        gt_end = gt_end.timestamp() if isinstance(gt_end, pd.Timestamp) else float(gt_end)
        
        # ì •ë‹µ ë¹„ë””ì˜¤ì´ê³  ì‹œê°„ì´ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸
        if result_video_id == video_id:
            time_overlap = (
                (start_time <= gt_start <= end_time) or
                (start_time <= gt_end <= end_time) or
                (gt_start <= start_time <= gt_end)
            )
            if time_overlap:
                found = True
                rank = i
                max_similarity = similarity
                break
    
    # ê²°ê³¼ ì €ì¥ - similarityë¥¼ floatë¡œ ë³€í™˜
    result_info = {
        'query': query,
        'video_id': video_id,
        'found': found,
        'rank': rank,
        'similarity': float(max_similarity),  # float32ë¥¼ floatë¡œ ë³€í™˜
        'gt_start': float(gt_start),         # í˜¹ì‹œ ëª¨ë¥¼ ë‹¤ë¥¸ float32 ê°’ë“¤ë„ ë³€í™˜
        'gt_end': float(gt_end)
    }
    metrics['detailed_results'].append(result_info)
    
    # í†µê³„ ì—…ë°ì´íŠ¸ - similarityë¥¼ floatë¡œ ë³€í™˜
    if found:
        metrics['found_in_topk'] += 1
        metrics['mean_rank'] += rank
        metrics['mean_similarity'] += float(max_similarity)
    
    # ê²°ê³¼ ì¶œë ¥
    status = "âœ… ë°œê²¬" if found else "âŒ ë¯¸ë°œê²¬"
    print(f"{status} (ìˆœìœ„: {rank if found else 'N/A'}, ìœ ì‚¬ë„: {max_similarity:.4f})")
    print(f"   ê°€ì¥ ìœ ì‚¬í•˜ë‹¤ê³  íŒë‹¨í•œ ìº¡ì…˜: {results[0][0]}")

# í‰ê·  ê³„ì‚°
if metrics['found_in_topk'] > 0:
    metrics['mean_rank'] /= metrics['found_in_topk']
    metrics['mean_similarity'] /= metrics['found_in_topk']

print("\nğŸ“ˆ í‰ê°€ ê²°ê³¼:")
print(f"ì´ ì¿¼ë¦¬ ìˆ˜: {metrics['total_queries']}")
print(f"ë°œê²¬ëœ ì¿¼ë¦¬ ìˆ˜: {metrics['found_in_topk']}")
print(f"í‰ê·  ìˆœìœ„: {metrics['mean_rank']:.2f}")
print(f"í‰ê·  ìœ ì‚¬ë„: {metrics['mean_similarity']:.4f}")
