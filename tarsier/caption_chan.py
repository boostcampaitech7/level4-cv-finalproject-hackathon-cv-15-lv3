import os
import json
import time
import torch
from utils import load_model_and_processor
from tqdm import tqdm
import threading

# âœ… ë°°ì¹˜ ìº¡ì…˜ ìƒì„± í•¨ìˆ˜ (batch_size=2)
def generate_captions_batch(model, processor, video_paths, max_n_frames=8, max_new_tokens=512, top_p=1, temperature=0.8):
    """Batch í¬ê¸°ë§Œí¼ ë™ì˜ìƒì—ì„œ ìº¡ì…˜ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    
    modified_prompt = "<video>\n Describe the video in detail."
    
    inputs_list = []
    for video_path in video_paths:
        inputs = processor(modified_prompt, video_path, edit_prompt=True, return_prompt=True)
        inputs.pop('prompt', None)  # í•„ìš” ì—†ëŠ” prompt ì œê±°
        inputs = {k: v.to(model.device) for k, v in inputs.items() if v is not None}
        inputs_list.append(inputs)
    
    # ë°°ì¹˜ ì…ë ¥ ìƒì„± (ê° ì…ë ¥ì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬)
    batch_inputs = {k: torch.cat([inputs[k] for inputs in inputs_list], dim=0) for k in inputs_list[0]}

    # âœ… ëª¨ë¸ ì‹¤í–‰ (Batch ì²˜ë¦¬)
    outputs = model.generate(
        **batch_inputs,
        do_sample=True,
        max_new_tokens=max_new_tokens,
        top_p=top_p,
        temperature=temperature,
        use_cache=True
    )

    # ê²°ê³¼ ë””ì½”ë”©
    captions = []
    for i, inputs in enumerate(inputs_list):
        output_text = processor.tokenizer.decode(outputs[i][inputs['input_ids'][0].shape[0]:], skip_special_tokens=True)
        captions.append(output_text)

    return captions

# âœ… ê²½ë¡œ ì„¤ì •
video_base_path = "/hdd1/lim_data/YouTube-8M-video-7sec_clips"
json_file_path = "/home/hwang/leem/level4-cv-finalproject-hackathon-cv-15-lv3/tarsier/7sec.json"
captioned_json_file_path = "/home/hwang/leem/level4-cv-finalproject-hackathon-cv-15-lv3/tarsier/7sec.json"

model_path = "/home/hwang/leem/level4-cv-finalproject-hackathon-cv-15-lv3/Tarsier-7b"
error_log_path = "error_log.txt"

# âœ… ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ
print("ğŸš€ ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘...")
model, processor = load_model_and_processor(model_path, max_n_frames=8)
model.half()
model.eval()

# âœ… ê¸°ì¡´ JSON íŒŒì¼ ë¡œë“œ
with open(json_file_path, 'r', encoding="utf-8") as f:
    video_metadata = json.load(f)

# âœ… ê¸°ì¡´ ìº¡ì…˜ í™•ì¸ í›„, ì—†ëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬
for video in video_metadata:
    if 'caption' not in video:
        video['caption'] = None

# âœ… ì „ì²´ í”„ë¡œì„¸ìŠ¤ íƒ€ì´ë¨¸ ì‹œì‘
start_time = time.time()

# âœ… ë°°ì¹˜ í¬ê¸° ì„¤ì •
batch_size = 2

# âœ… ì˜¤ë¥˜ ì œì™¸ëœ ë¦¬ìŠ¤íŠ¸ (í•„ìš” ì‹œ ìˆ˜ì • ê°€ëŠ¥)
error_index = []

# âœ… Batch-wise ì§„í–‰
print(f"ğŸ“Š ì´ {len(video_metadata)} ê°œì˜ ë¹„ë””ì˜¤ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. (Batch Size: {batch_size})")

for i in tqdm(range(0, len(video_metadata), batch_size), desc="Processing Videos"):
    batch_videos = video_metadata[i:i + batch_size]

    # âœ… ê¸°ì¡´ì²˜ëŸ¼ ê° ì˜ìƒ ê°œë³„ ì¶œë ¥ ìœ ì§€
    for video in batch_videos:
        print(f" {i}/{len(video_metadata)} {video['video_path']}")

    # âœ… ë¹„ë””ì˜¤ ê²½ë¡œ í•„í„°ë§
    batch_video_paths = [
        os.path.join(video_base_path, video["video_path"])
        for video in batch_videos
        if os.path.exists(os.path.join(video_base_path, video["video_path"]))
    ]

    if not batch_video_paths:
        continue  # ì²˜ë¦¬í•  ë¹„ë””ì˜¤ê°€ ì—†ìœ¼ë©´ ë„˜ì–´ê°

    timer = threading.Timer(20, lambda: print(f"â³ Timeout: {batch_video_paths}"))
    timer.start()

    try:
        # âœ… ë°°ì¹˜ ìº¡ì…˜ ìƒì„± ìˆ˜í–‰
        captions = generate_captions_batch(model, processor, batch_video_paths, temperature=0.8)

        # âœ… ìº¡ì…˜ ì¶”ê°€
        for video, caption in zip(batch_videos, captions):
            video["caption"] = caption
        
        # âœ… ì£¼ê¸°ì ìœ¼ë¡œ JSON ì €ì¥ (20ë²ˆì§¸ ë£¨í”„ë§ˆë‹¤)
        if i % 20 == 1:
            with open(captioned_json_file_path, "w", encoding="utf-8") as f:
                json.dump(video_metadata, f, indent=4)
            print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ {i}/{len(video_metadata)} : {video['video_path']}")

    except Exception as e:
        print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # ì˜¤ë¥˜ ë°œìƒ ì‹œ JSON ì €ì¥
        with open(captioned_json_file_path, "w", encoding="utf-8") as f:
            json.dump(video_metadata, f, indent=4)

        # ì˜¤ë¥˜ ë¡œê·¸ ì €ì¥
        with open(error_log_path, "a", encoding="utf-8") as error_log:
            error_log.write(f"ì˜¤ë¥˜ ë°œìƒ! ë¹„ë””ì˜¤ ê²½ë¡œ: {batch_video_paths}\n")

        continue  # ë‹¤ìŒ ë°°ì¹˜ë¡œ ì´ë™
    finally:
        timer.cancel()  # íƒ€ì´ë¨¸ ì·¨ì†Œ

# âœ… ìµœì¢… JSON íŒŒì¼ ì €ì¥
with open(captioned_json_file_path, "w", encoding="utf-8") as f:
    json.dump(video_metadata, f, indent=4)

# âœ… ì „ì²´ í”„ë¡œì„¸ìŠ¤ íƒ€ì´ë¨¸ ì¢…ë£Œ
end_time = time.time()
print(f"âœ… ì´ ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")