import os
import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer

class CaptionMatcher:
    def __init__(self, model_path, test_json_path):
        """
        ëª¨ë¸ê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        :param model_path: SentenceTransformer ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ
        :param test_json_path: í…ŒìŠ¤íŠ¸ ë°ì´í„° JSON íŒŒì¼ ê²½ë¡œ
        """
        self.model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')  # ë¡œì»¬ ëª¨ë¸ ë¡œë“œ
        #self.model = SentenceTransformer(model_path)  # ë¡œì»¬ ëª¨ë¸ ë¡œë“œ
        self.test_json_path = test_json_path
        self.test_data = self.load_test_data()

    def load_test_data(self):
        """JSON íŒŒì¼ì—ì„œ Test ë°ì´í„° ë¡œë“œ"""
        if not os.path.exists(self.test_json_path):
            print(f"ğŸš¨ ì˜¤ë¥˜: {self.test_json_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return []

        with open(self.test_json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        print(f"ğŸ“‚ Loaded {len(data)} samples from {self.test_json_path}")
        print(f"ğŸ” First entry preview: {data[0] if len(data) > 0 else 'No data'}")

        return data

    def generate_embeddings(self):
        """ì¿¼ë¦¬(1ë²ˆ)ì™€ ìº¡ì…˜(0ë²ˆ)ì˜ ì„ë² ë”© ìƒì„±"""
        captions = [entry[0] for entry in self.test_data]  # ìº¡ì…˜
        queries = [entry[1] for entry in self.test_data]  # ì¿¼ë¦¬

        caption_embeddings = self.model.encode(captions, convert_to_numpy=True)
        query_embeddings = self.model.encode(queries, convert_to_numpy=True)

        return captions, queries, caption_embeddings, query_embeddings

    def build_faiss_index(self, caption_embeddings):
        """Faiss ì¸ë±ìŠ¤ ìƒì„± (ìº¡ì…˜ ì„ë² ë”© ì €ì¥)"""
        d = caption_embeddings.shape[1]  # ë²¡í„° ì°¨ì›
        index = faiss.IndexFlatIP(d)  # ë‚´ì ì„ ì‚¬ìš©í•œ Index ìƒì„± (Cosine ìœ ì‚¬ë„ì— í™œìš©)
        faiss.normalize_L2(caption_embeddings)  # L2 ì •ê·œí™” â†’ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ì™€ ë™ì¼í•œ íš¨ê³¼
        index.add(caption_embeddings)

        return index

    def test_matching(self, top_k=5):
        """ì¿¼ë¦¬ì™€ ìº¡ì…˜ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ ìˆ˜í–‰"""
        captions, queries, caption_embeddings, query_embeddings = self.generate_embeddings()
        index = self.build_faiss_index(caption_embeddings)

        # L2 ì •ê·œí™” (Cosine Similarity í™œìš©)
        faiss.normalize_L2(query_embeddings)

        # Faiss ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ Top-K ê²€ìƒ‰
        distances, retrieved_indices = index.search(query_embeddings, top_k)

        # ê²°ê³¼ ì €ì¥
        results = []
        for i, query in enumerate(queries):
            retrieved_captions = [captions[idx] for idx in retrieved_indices[i]]
            retrieved_scores = distances[i].tolist()  # ìœ ì‚¬ë„ ì ìˆ˜

            results.append({
                "query": query,
                "ground_truth_caption": captions[i],  # ì›ë˜ ë§¤ì¹­ëœ ìº¡ì…˜
                "retrieved_captions": retrieved_captions,  # ìœ ì‚¬í•œ ìº¡ì…˜ ë¦¬ìŠ¤íŠ¸
                "retrieved_scores": retrieved_scores  # ìœ ì‚¬ë„ ì ìˆ˜
            })

        return results

    def compute_accuracy(self, results):
        """Top-1 ë° Top-5 ê¸°ì¤€ ì •ë‹µë¥  ê³„ì‚°"""
        total_samples = len(results)
        top1_correct = 0
        top5_correct = 0

        for result in results:
            ground_truth = result["ground_truth_caption"]
            retrieved_captions = result["retrieved_captions"]

            if ground_truth == retrieved_captions[0]:  # Top-1 ë§¤ì¹­ í™•ì¸
                top1_correct += 1
            if ground_truth in retrieved_captions:  # Top-5 ë§¤ì¹­ í™•ì¸
                top5_correct += 1

        top1_accuracy = top1_correct / total_samples * 100
        top5_accuracy = top5_correct / total_samples * 100

        print(f"ğŸ¯ Top-1 Accuracy: {top1_accuracy:.2f}% ({top1_correct}/{total_samples})")
        print(f"ğŸ¯ Top-5 Accuracy: {top5_accuracy:.2f}% ({top5_correct}/{total_samples})")

        return top1_accuracy, top5_accuracy

    def save_results(self, output_path, top_k=5):
        """ë§¤ì¹­ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥ + Accuracy ì¶œë ¥"""
        results = self.test_matching(top_k)

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=4)
        print(f"âœ… Test ë§¤ì¹­ ê²°ê³¼ ì €ì¥ ì™„ë£Œ â†’ {output_path}")

        # ğŸ”¹ ì •ë‹µë¥  ê³„ì‚°
        self.compute_accuracy(results)

# âœ… ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    model_path = "/data/ephemeral/home/finetune/final"  # ë¯¸ë¦¬ í›ˆë ¨ëœ ëª¨ë¸ ê²½ë¡œ
    test_json_path = "/data/ephemeral/home/level4-cv-finalproject-hackathon-cv-15-lv3/embedding_train/data_train_test/test_sentence_pairs.json"  # Test ë°ì´í„°ì…‹
    output_json_path = "/data/ephemeral/home/level4-cv-finalproject-hackathon-cv-15-lv3/embedding_train/data_train_test/test_results.json"  # ê²°ê³¼ ì €ì¥ ê²½ë¡œ

    matcher = CaptionMatcher(model_path, test_json_path)
    matcher.save_results(output_json_path, top_k=5)  # Top-5 ìœ ì‚¬ ë¬¸ì¥ ì €ì¥
