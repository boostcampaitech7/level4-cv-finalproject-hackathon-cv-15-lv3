from abc import ABC, abstractmethod
import cv2
from moviepy import VideoFileClip
from scenedetect import detect, ContentDetector, AdaptiveDetector
from contextlib import contextmanager, redirect_stdout, redirect_stderr
import os

@contextmanager
def suppress_output():
    """ëª¨ë“  ì¶œë ¥ì„ ì–µì œí•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    with open(os.devnull, 'w') as devnull:
        with redirect_stdout(devnull), redirect_stderr(devnull):
            yield


class VideoSegmenter(ABC):
    """ë¹„ë””ì˜¤ ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìœ„í•œ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def get_segments(self, video_path):
        """ë¹„ë””ì˜¤ íŒŒì¼ì„ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë‚˜ëˆ„ëŠ” ë©”ì„œë“œ
        
        Args:
            video_path (str): ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            list of tuple: (start_time, end_time) í˜•íƒœì˜ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        pass

class FixedDurationSegmenter(VideoSegmenter):
    """ê³ ì • ê¸¸ì´ë¡œ ë¹„ë””ì˜¤ë¥¼ ë‚˜ëˆ„ëŠ” ì„¸ê·¸ë©˜í„°"""
    
    def __init__(self, segment_duration=5):
        self.segment_duration = segment_duration
    
    def get_segments(self, video_path):
        with suppress_output():
            with VideoFileClip(video_path) as video:
                duration = video.duration
                segments = []
                start_time = 0
                
                while start_time < duration:
                    end_time = min(start_time + self.segment_duration, duration)
                    if end_time - start_time >= 1:  # ìµœì†Œ 1ì´ˆ ì´ìƒì¸ ì„¸ê·¸ë¨¼íŠ¸ë§Œ í¬í•¨
                        segments.append((start_time, end_time))
                    start_time = end_time
                
        return segments

# class SceneDetectionSegmenter(VideoSegmenter):
#     """Scene detectionì„ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ë¥¼ ë‚˜ëˆ„ëŠ” ì„¸ê·¸ë©˜í„°"""
    
#     def __init__(self, adaptive_threshold=3.0, min_scene_len=30):
#         """
#         Args:
#             adaptive_threshold (float): ì¥ë©´ ë³€í™” ê°ì§€ ë¯¼ê°ë„ (ë‚®ì„ìˆ˜ë¡ ë” ë¯¼ê°)
#                                      - 2.0: ë” ë¯¼ê°í•œ ê°ì§€
#                                      - 3.0: ê¸°ë³¸ê°’, ì¼ë°˜ì ì¸ ìš©ë„
#                                      - 4.0: ëœ ë¯¼ê°í•œ ê°ì§€
#             min_scene_len (int): ìµœì†Œ ì¥ë©´ ê¸¸ì´ (í”„ë ˆì„ ë‹¨ìœ„)
#                                - 15: ê¸°ë³¸ê°’ (~0.5ì´ˆ @ 30fps)
#                                - 10: ì§§ì€ ì¥ë©´ í—ˆìš©
#                                - 30: ê¸´ ì¥ë©´ ë³´ì¥
#         """
#         self.adaptive_threshold = adaptive_threshold
#         self.min_scene_len = min_scene_len
    
#     def get_segments(self, video_path):
#         try:
#             # Scene detection ì‹¤í–‰
#             scenes = detect(video_path, AdaptiveDetector(
#                 adaptive_threshold=self.adaptive_threshold,
#                 min_scene_len=self.min_scene_len
#             ))
            
#             # (start_time, end_time) í˜•íƒœë¡œ ë³€í™˜
#             segments = [(scene[0].get_seconds(), scene[1].get_seconds()) 
#                        for scene in scenes]
            
#             # ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
#             if not segments:
#                 print(f"âš ï¸ No scenes detected in {video_path}, using entire video")
#                 with VideoFileClip(video_path) as video:
#                     segments = [(0, video.duration)]
            
#             return segments
            
#         except Exception as e:
#             print(f"ğŸš¨ Error during scene detection for {video_path}: {str(e)}")
#             # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì „ì²´ ë¹„ë””ì˜¤ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ
#             with VideoFileClip(video_path) as video:
#                 return [(0, video.duration)]

class SceneDetectionSegmenter(VideoSegmenter):
    """Scene detectionì„ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ë¥¼ ë‚˜ëˆ„ëŠ” ì„¸ê·¸ë©˜í„°"""
    
    def __init__(self, threshold=27.0, min_scene_len=30):
        """
        Args:
            threshold (float): ì¥ë©´ ë³€í™” ê°ì§€ë¥¼ ìœ„í•œ ì„ê³„ê°’
                             - ë‚®ì„ìˆ˜ë¡ ë” ë¯¼ê°í•˜ê²Œ ê°ì§€
                             - 27.0: ê¸°ë³¸ê°’
                             - 20.0: ë” ë¯¼ê°í•œ ê°ì§€
                             - 35.0: ëœ ë¯¼ê°í•œ ê°ì§€
            min_scene_len (int): ìµœì†Œ ì¥ë©´ ê¸¸ì´ (í”„ë ˆì„ ë‹¨ìœ„)
                               - 15: ê¸°ë³¸ê°’ (~0.5ì´ˆ @ 30fps)
                               - 10: ì§§ì€ ì¥ë©´ í—ˆìš©
                               - 30: ê¸´ ì¥ë©´ ë³´ì¥
        """
        self.threshold = threshold
        self.min_scene_len = min_scene_len
    
    def get_segments(self, video_path):
        try:
            # Scene detection ì‹¤í–‰
            scenes = detect(video_path, ContentDetector(
                threshold=self.threshold,
                min_scene_len=self.min_scene_len
            ))
            
            # (start_time, end_time) í˜•íƒœë¡œ ë³€í™˜
            segments = [(scene[0].get_seconds(), scene[1].get_seconds()) 
                       for scene in scenes]
            
            # ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
            if not segments:
                print(f"âš ï¸ No scenes detected in {video_path}, using entire video")
                with VideoFileClip(video_path) as video:
                    segments = [(0, video.duration)]
            
            return segments
            
        except Exception as e:
            print(f"ğŸš¨ Error during scene detection for {video_path}: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì „ì²´ ë¹„ë””ì˜¤ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ
            with VideoFileClip(video_path) as video:
                return [(0, video.duration)]

class ShotBoundarySegmenter(VideoSegmenter):
    """Shot boundary detectionì„ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ë¥¼ ë‚˜ëˆ„ëŠ” ì„¸ê·¸ë©˜í„°"""
    
    def __init__(self, threshold=30, min_segment_length=1):
        self.threshold = threshold
        self.min_segment_length = min_segment_length
    
    def get_segments(self, video_path):
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        segments = []
        
        if not cap.isOpened():
            print(f"ğŸš¨ Error: Could not open video {video_path}")
            return segments
        
        try:
            prev_frame = None
            start_time = 0
            frame_count = 0
            
            while frame_count < total_frames:  # total_framesë¡œ ì²´í¬
                ret, frame = cap.read()
                if not ret:
                    break
                
                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜í•˜ì—¬ ê³„ì‚° íš¨ìœ¨ì„± í–¥ìƒ
                frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                
                if prev_frame is not None:
                    # í”„ë ˆì„ ê°„ ì°¨ì´ ê³„ì‚° (ê·¸ë ˆì´ìŠ¤ì¼€ì¼)
                    diff = cv2.absdiff(frame_gray, prev_frame)
                    score = diff.mean()
                    
                    # Shot boundary ê°ì§€
                    if score > self.threshold:
                        end_time = frame_count / fps
                        if end_time - start_time >= self.min_segment_length:
                            segments.append((start_time, end_time))
                        start_time = end_time
                
                prev_frame = frame_gray  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ ì €ì¥
                frame_count += 1
            
            # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
            end_time = frame_count / fps
            if end_time - start_time >= self.min_segment_length:
                segments.append((start_time, end_time))
            
        except Exception as e:
            print(f"ğŸš¨ Error processing video {video_path}: {str(e)}")
        
        finally:
            cap.release()
        
        # ë¹ˆ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì „ì²´ ë¹„ë””ì˜¤ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ
        if not segments:
            print(f"âš ï¸ No segments detected for {video_path}, using entire video")
            segments = [(0, total_frames / fps)]
        
        return segments

# Factory íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ì„¸ê·¸ë©˜í„° ìƒì„±
def create_segmenter(method="fixed", **kwargs):
    """ì„¸ê·¸ë©˜í„° ìƒì„± í•¨ìˆ˜
    
    Args:
        method (str): ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ("fixed", "scene", "shot")
        **kwargs: ê° ì„¸ê·¸ë©˜í„°ì˜ íŒŒë¼ë¯¸í„°
    
    Returns:
        VideoSegmenter: ì„¸ê·¸ë©˜í„° ì¸ìŠ¤í„´ìŠ¤
    """
    segmenters = {
        "fixed": FixedDurationSegmenter,
        "scene": SceneDetectionSegmenter,
        "shot": ShotBoundarySegmenter
    }
    
    if method not in segmenters:
        raise ValueError(f"Unknown segmentation method: {method}")
    
    return segmenters[method](**kwargs)