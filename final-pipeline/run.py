import argparse
import yaml
import json
import os
import sys
import time
import subprocess
from utils.translator import DeepGoogleTranslator, DeepLTranslator
from video_to_text.video_captioning import TarsierVideoCaptioningPipeline
from text_to_video.embedding import FaissSearch
from split_process.main_server.main_server_run import main as split_process_main
from split_process.main_server.config import Config as SplitConfig

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def video_to_text_process():
    """ë¹„ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” íŒŒì´í”„ë¼ì¸"""
    print("\nğŸš€ ë¹„ë””ì˜¤-í…ìŠ¤íŠ¸ ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
    process_start_time = time.time()
    
    # YAML ì„¤ì • íŒŒì¼ ë¡œë“œ
    try:
        with open('video2text_input.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except Exception as e:
        print(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return

    # ê¸°ë³¸ ì„¤ì •ê°’ (ì½”ë“œë¡œ ê´€ë¦¬)
    KEEP_CLIPS = True  # í´ë¦½ ì €ì¥ì„ ìœ„í•´ Trueë¡œ ë³€ê²½
    current_dir = os.path.dirname(os.path.abspath(__file__))
    model_path = "/data/ephemeral/home/Tarsier-7b"
    clips_dir = os.path.join(current_dir, "clips/video2text/")  # í´ë¦½ ì €ì¥ ê²½ë¡œ
    
    # clips ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(clips_dir, exist_ok=True)

    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    pipeline = TarsierVideoCaptioningPipeline(
        model_path=model_path,
        keep_clips=KEEP_CLIPS,
        mode="video2text",
        video_metadata={},
        clips_dir=clips_dir  # í´ë¦½ ì €ì¥ ê²½ë¡œ ì§€ì •
    )
    
    # ë¹„ë””ì˜¤ ì²˜ë¦¬
    video_list = []
    for video_data in config.get('videos', []):
        video_path = video_data['video_id']
        
        if not os.path.exists(video_path):
            print(f"âš ï¸ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {video_path}")
            continue
        
        video_list.extend([
            (video_path, ts['start_time'], ts['end_time'])
            for ts in video_data['timestamps']
        ])
    
    if not video_list:
        print("âŒ ì²˜ë¦¬í•  ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° ìº¡ì…˜ ìƒì„±
    result_txt_path = os.path.join(clips_dir, "captioning_result.txt")
    with open(result_txt_path, 'w', encoding='utf-8') as f:
        # ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° ìº¡ì…˜ ìƒì„±
        print(f"\nğŸ¥ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘... (ì´ {len(video_list)}ê°œ í´ë¦½)")
        f.write(f"\nğŸ¥ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘... (ì´ {len(video_list)}ê°œ í´ë¦½)\n")
        results = []
        for idx, (video_path, start_time, end_time) in enumerate(video_list, 1):
            process_msg = f"\nì²˜ë¦¬ ì¤‘: {idx}/{len(video_list)} - {os.path.basename(video_path)} ({start_time}ì´ˆ ~ {end_time}ì´ˆ)"
            print(process_msg)
            f.write(process_msg + "\n")
            
            result = pipeline.process_video(video_path, start_time, end_time)
            if result:
                results.append(result)
                print(f"âœ… ì™„ë£Œ")
                f.write("âœ… ì™„ë£Œ\n")
        
        # ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“ ìƒì„±ëœ ìº¡ì…˜:")
        print("=" * 80)
        f.write("\nğŸ“ ìƒì„±ëœ ìº¡ì…˜:\n")
        f.write("=" * 80 + "\n")
        
        for i, ((original_path, start_time, end_time), result) in enumerate(zip(video_list, results), 1):
            if 'YouTube_8M/YouTube_8M_video' in original_path:
                video_name = os.path.basename(original_path)
                mapping_path = './videos/YouTube_8M/YouTube_8M_annotation/Movieclips_annotation.json'
                
                try:
                    with open(mapping_path, 'r', encoding='utf-8') as map_f:
                        mapping_data = json.load(map_f)
                        video_info = next(
                            (item for item in mapping_data if item['video_name'] == video_name),
                            None
                        )
                        if video_info:
                            video_title = video_info['title']
                            clip_info = f"\nğŸ¬ í´ë¦½ {i}: {video_title} (ID: {video_name})"
                        else:
                            clip_info = f"\nğŸ¬ í´ë¦½ {i}: {video_name}"
                except Exception as e:
                    clip_info = f"\nğŸ¬ í´ë¦½ {i}: {video_name}"
            else:
                video_name = os.path.basename(original_path)
                clip_info = f"\nğŸ¬ í´ë¦½ {i}: {video_name}"
            
            print(clip_info)
            f.write(clip_info + "\n")
            
            result_info = f"â° êµ¬ê°„: {result['start_time']}ì´ˆ ~ {result['end_time']}ì´ˆ\nê²°ê³¼: {result['caption_ko']}"
            print(result_info)
            f.write(result_info + "\n")
            
            separator = "-" * 80
            print(separator)
            f.write(separator + "\n")
        
        # ê²°ê³¼ ì¶œë ¥ í›„ ì‹œê°„ ê³„ì‚°
        total_time = time.time() - process_start_time
        minutes, seconds = divmod(total_time, 60)
        
        if minutes >= 60:
            hours, minutes = divmod(minutes, 60)
            time_msg = f"\nâœ¨ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ (ì´ {int(hours)}ì‹œê°„ {int(minutes)}ë¶„ {seconds:.1f}ì´ˆ)"
        else:
            time_msg = f"\nâœ¨ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ (ì´ {int(minutes)}ë¶„ {seconds:.1f}ì´ˆ)"
        
        print(time_msg)
        f.write(time_msg + "\n")
        
        summary = f"ğŸ“Š ì²˜ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸: {len(results)}/{len(video_list)}\nğŸ’¾ í´ë¦½ ì €ì¥ ìœ„ì¹˜: {clips_dir}"
        print(summary)
        f.write(summary + "\n")
    
    print(f"ğŸ“ ê²°ê³¼ê°€ ì €ì¥ë¨: {result_txt_path}")

def save_search_clip(video_path, output_path, start_time, end_time):
    """ê²€ìƒ‰ ê²°ê³¼ ë¹„ë””ì˜¤ í´ë¦½ì„ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    command = [
        "ffmpeg",
        "-ss", str(start_time),
        "-i", video_path,
        "-t", str(end_time - start_time),
        "-c", "copy",
        output_path,
        "-y"
    ]
    
    subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

def text_to_video_search():
    """í…ìŠ¤íŠ¸ë¡œ ë¹„ë””ì˜¤ ê²€ìƒ‰í•˜ëŠ” íŒŒì´í”„ë¼ì¸"""
    print("\nğŸš€ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
    start_time = time.time()
    
    # YAML ì„¤ì • íŒŒì¼ ë¡œë“œ
    try:
        with open('text2video_input.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except Exception as e:
        print(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return

    queries = config.get('queries', [])
    process_new = config.get('process_new', False)
    new_videos_dir = config.get('new_videos_dir', '')
    top_k = config.get('top_k', 1)

    # DB ê²½ë¡œ ì„¤ì •
    main_db_path = "database/caption_embedding_tf_357_final4.json"
    new_db_path = "output/text2video/new_videos_captions.json"
    temp_db_path = "output/text2video/temp_combined_db.json"

    # ìƒˆë¡œìš´ ë¹„ë””ì˜¤ê°€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
    if process_new and new_videos_dir and os.path.exists(new_videos_dir):
        if not os.path.exists(temp_db_path):  # temp_combined_dbê°€ ì—†ëŠ” ê²½ìš°ë§Œ ìƒˆë¡œ ìƒì„±
            print(f"\nğŸ¥ ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘... ({new_videos_dir})")
            
            # ì„¤ì • ì—…ë°ì´íŠ¸ ë° ë¶„ì‚° ì²˜ë¦¬
            SplitConfig.VIDEOS_DIR = new_videos_dir
            SplitConfig.SPLIT_VIDEOS_DIR = os.path.join(new_videos_dir, "split")
            
            print("ğŸ“¦ ì™¸ë¶€ ë¹„ë””ì˜¤ ì „ì²˜ë¦¬ ì‹œì‘...")
            process_start_time = time.time()
            split_process_main()
            
            # JSON ê²°ê³¼ ì·¨í•©
            print("\nğŸ“Š ì™¸ë¶€ ë¹„ë””ì˜¤ ì „ì²˜ë¦¬ ê²°ê³¼ ì·¨í•© ì¤‘...")
            json_results = []
            json_dir = "/data/ephemeral/home/json"
            
            for json_file in os.listdir(json_dir):
                if json_file.startswith("video_files_") and json_file.endswith(".json"):
                    with open(os.path.join(json_dir, json_file), 'r') as f:
                        json_results.extend(json.load(f))
            
            # ìƒˆ ê²°ê³¼ë¥¼ DBì— ì €ì¥
            with open(new_db_path, 'w', encoding='utf-8') as f:
                json.dump(json_results, f, indent=4, ensure_ascii=False)
            
            # temp_combined_db ìƒì„±
            print("ğŸ”„ í†µí•© DB ìƒì„± ì¤‘...")
            with open(main_db_path, 'r', encoding='utf-8') as f:
                combined_data = json.load(f)
            combined_data.extend(json_results)
            
            with open(temp_db_path, 'w', encoding='utf-8') as f:
                json.dump(combined_data, f, indent=4, ensure_ascii=False)
            
            external_data_preprocessing_time = time.time() - process_start_time
            print(f"â±ï¸ ì™¸ë¶€ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ ì‹œê°„ ({external_data_preprocessing_time:.1f}ì´ˆ)")
    
    # í´ë¦½ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    current_dir = os.path.dirname(os.path.abspath(__file__))
    search_clips_dir = os.path.join(current_dir, "clips/text2video/")
    os.makedirs(search_clips_dir, exist_ok=True)

    # ê²€ìƒ‰ ê²°ê³¼ ì €ì¥í•  txt íŒŒì¼ ìƒì„±
    result_txt_path = os.path.join(search_clips_dir, "retrieval_result.txt")
    with open(result_txt_path, 'w', encoding='utf-8') as f:
        # FAISS ê²€ìƒ‰
        search_time = time.time()
        translator = DeepLTranslator()
        
        # DB ì„ íƒ
        if process_new and os.path.exists(temp_db_path):
            search_db_path = temp_db_path
            print("ğŸ” í†µí•© DBì—ì„œ ê²€ìƒ‰ ì¤€ë¹„ ì¤‘...")
        else:
            search_db_path = main_db_path
            print("ğŸ” ê¸°ë³¸ DBì—ì„œ ê²€ìƒ‰ ì¤€ë¹„ ì¤‘...")
        
        faiss_search = FaissSearch(json_path=search_db_path)
        all_results = {}  # ëª¨ë“  ì¿¼ë¦¬ì˜ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
        
        print(f"\nì´ {len(queries)}ê°œì˜ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘...")
        
        for query_idx, query_text in enumerate(queries, 1):
            print(f"\nğŸ“ ì¿¼ë¦¬ {query_idx}/{len(queries)}: '{query_text}'")
            
            similar_captions = faiss_search.find_similar_captions(query_text, translator, top_k=top_k)
            all_results[query_text] = similar_captions
            
            external_video_dir = "./videos/input_video"
            youtube_videos_dir = "./videos/YouTube_8M/YouTube_8M_video"

            # ê° ì¿¼ë¦¬ì˜ ê²°ê³¼ ì¶œë ¥ ë° í´ë¦½ ì €ì¥
            print(f"\nğŸ¯ '{query_text}'ì˜ ê²€ìƒ‰ ê²°ê³¼:")
            f.write(f"\nê²€ìƒ‰ ê²°ê³¼:\n")
            for i, (similarity, video_info) in enumerate(similar_captions, 1):
                video_path = video_info['video_path']
                video_start_time = float(video_info['start_time'])
                video_end_time = float(video_info['end_time'])
                
                # video_id ìœ ë¬´ì— ë”°ë¼ ë¹„ë””ì˜¤ ê²½ë¡œ ê²°ì •
                if 'video_id' in video_info and video_info['video_id']:
                    # YouTube ë¹„ë””ì˜¤ì¸ ê²½ìš° ê²½ë¡œ ìˆ˜ì •
                    video_folder = video_path.split('/')[0]
                    full_video_path = os.path.join(youtube_videos_dir, f"{video_folder}.mp4")
                else:
                    # ì™¸ë¶€ ì…ë ¥ ë¹„ë””ì˜¤ì¸ ê²½ìš°
                    full_video_path = os.path.join(external_video_dir, video_path)
                
                if not os.path.exists(full_video_path):
                    print(f"  âš ï¸ ì›ë³¸ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {video_path}")
                    continue
                    
                # í´ë¦½ íŒŒì¼ëª… ìƒì„±
                query_slug = "_".join(query_text.split())[:30]
                base_video_name = os.path.splitext(os.path.basename(video_path))[0]
                if 'video_id' in video_info and video_info['video_id']:
                    # YouTube ë¹„ë””ì˜¤ì¸ ê²½ìš° í´ë”ëª…ì„ ì‚¬ìš©
                    base_video_name = video_path.split('/')[0]
                clip_filename = f"{query_slug}_rank{i}_{base_video_name}_{video_start_time}_{video_end_time}.mp4"
                clip_path = os.path.join(search_clips_dir, clip_filename)
                
                try:
                    # ffmpegë¡œ ë¹„ë””ì˜¤ í´ë¦½ ì¶”ì¶œ
                    save_search_clip(full_video_path, clip_path, video_start_time, video_end_time)
                    print(f"  ğŸ’¾ í´ë¦½ ì €ì¥: {clip_filename}")
                except Exception as e:
                    print(f"  âš ï¸ í´ë¦½ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
                
                # í´ë¦½ ì €ì¥ ê²°ê³¼ë¥¼ txtì— ê¸°ë¡
                result_text = f"""
ê²°ê³¼
ğŸ“Š ìœ ì‚¬ë„: {similarity:.4f}
ğŸ¬ ë¹„ë””ì˜¤: {os.path.basename(video_path)}
â° êµ¬ê°„: {video_start_time}ì´ˆ ~ {video_end_time}ì´ˆ
ğŸ“ ì œëª©: {video_info['title']}
ğŸ” ê²€ìƒ‰ì–´: {query_text}
ğŸ’¾ ì €ì¥ëœ í´ë¦½: {clip_filename if os.path.exists(clip_path) else 'ì €ì¥ ì‹¤íŒ¨'}
----------------------------------------
"""
                f.write(result_text)
                print(result_text)
                            
                f.write(f"\nê²€ìƒ‰ì–´ '{query_text}' ì²˜ë¦¬ ì™„ë£Œ\n")
                f.write("-" * 50 + "\n")
                        
                # ê²€ìƒ‰ ì™„ë£Œ ì •ë³´ ì €ì¥
                summary = f"""
\nê²€ìƒ‰ ìš”ì•½:
â€¢ ì´ ê²€ìƒ‰ì–´ ìˆ˜: {len(queries)}ê°œ
â€¢ ê²€ìƒ‰ ì†Œìš” ì‹œê°„: {time.time() - search_time:.1f}ì´ˆ
â€¢ í´ë¦½ ì €ì¥ ìœ„ì¹˜: {search_clips_dir}
â€¢ ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {time.time() - start_time:.1f}ì´ˆ
"""
                f.write(summary)
    
    print(f"\nâ±ï¸ ì „ì²´ ê²€ìƒ‰ ì™„ë£Œ ({time.time() - search_time:.1f}ì´ˆ)")
    print(f"ğŸ’¾ í´ë¦½ ì €ì¥ ìœ„ì¹˜: {search_clips_dir}")
    
    total_time = time.time() - start_time
    print(f"\nâœ¨ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ (ì´ {total_time:.1f}ì´ˆ)")

    return all_results

def main():
    parser = argparse.ArgumentParser(description='Video Processing Pipeline')
    parser.add_argument('mode', choices=['text2video', 'video2text'],
                      help='Choose pipeline mode: text2video or video2text')
    
    args = parser.parse_args()
    
    if args.mode == 'text2video':
        text_to_video_search()
    else:
        video_to_text_process()

if __name__ == "__main__":
    main()