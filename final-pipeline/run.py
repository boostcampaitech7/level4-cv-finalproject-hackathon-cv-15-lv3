import argparse
import yaml
import json
import os
import sys
import time
from tqdm import tqdm
from moviepy import VideoFileClip
from utils.translator import DeepGoogleTranslator, DeepLTranslator
from video_to_text.video_captioning import TarsierVideoCaptioningPipeline
from text_to_video.embedding import FaissSearch
from split_process.main_server.main_server_run import main as split_process_main
from split_process.main_server.config import Config as SplitConfig

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def save_search_result_clip(video_path, start_time, end_time, output_dir, clip_name):
    """ê²€ìƒ‰ ê²°ê³¼ í´ë¦½ì„ ì €ì¥"""
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        clip = VideoFileClip(video_path).subclipped(start_time, end_time)
        output_path = os.path.join(output_dir, f"{clip_name}.mp4")
        clip.write_videofile(output_path, codec='libx264', audio=False)
        clip.close()
        
        print(f"âœ… ê²€ìƒ‰ ê²°ê³¼ í´ë¦½ ì €ì¥ ì™„ë£Œ: {output_path}")
        return output_path
        
    except Exception as e:
        print(f"âŒ í´ë¦½ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def video_to_text_process():
    """ë¹„ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” íŒŒì´í”„ë¼ì¸"""
    print("\nğŸš€ ë¹„ë””ì˜¤-í…ìŠ¤íŠ¸ ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
    process_start_time = time.time()
    
    # YAML ì„¤ì • íŒŒì¼ ë¡œë“œ
    try:
        with open('video2text_input.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except Exception as e:
        print(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return

    # ê¸°ë³¸ ì„¤ì •ê°’ (ì½”ë“œë¡œ ê´€ë¦¬)
    KEEP_CLIPS = True  # í´ë¦½ ì €ì¥ì„ ìœ„í•´ Trueë¡œ ë³€ê²½
    current_dir = os.path.dirname(os.path.abspath(__file__))
    model_path = os.path.abspath(os.path.join(current_dir, "..", "..", "Tarsier-7b"))
    clips_dir = os.path.join(current_dir, "clips/video2text/")  # í´ë¦½ ì €ì¥ ê²½ë¡œ
    
    # clips ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(clips_dir, exist_ok=True)

    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    pipeline = TarsierVideoCaptioningPipeline(
        model_path=model_path,
        keep_clips=KEEP_CLIPS,
        mode="video2text",
        video_metadata={},
        clips_dir=clips_dir  # í´ë¦½ ì €ì¥ ê²½ë¡œ ì§€ì •
    )
    
    # ë¹„ë””ì˜¤ ì²˜ë¦¬
    video_list = []
    for video_data in config.get('videos', []):
        video_path = video_data['video_id']
        
        if not os.path.exists(video_path):
            print(f"âš ï¸ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {video_path}")
            continue
        
        video_list.extend([
            (video_path, ts['start_time'], ts['end_time'])
            for ts in video_data['timestamps']
        ])
    
    if not video_list:
        print("âŒ ì²˜ë¦¬í•  ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° ìº¡ì…˜ ìƒì„±
    print(f"\nğŸ¥ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘... (ì´ {len(video_list)}ê°œ í´ë¦½)")
    results = []
    for idx, (video_path, start_time, end_time) in enumerate(video_list, 1):
        print(f"\nì²˜ë¦¬ ì¤‘: {idx}/{len(video_list)} - {os.path.basename(video_path)} ({start_time}ì´ˆ ~ {end_time}ì´ˆ)")
        result = pipeline.process_video(video_path, start_time, end_time)
        if result:
            results.append(result)
            print(f"âœ… ì™„ë£Œ")
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“ ìƒì„±ëœ ìº¡ì…˜:")
    print("=" * 80)
    for i, ((original_path, start_time, end_time), result) in enumerate(zip(video_list, results), 1):
        # YouTube-8M ë¹„ë””ì˜¤ì¸ ê²½ìš° ë§¤í•‘ ì •ë³´ í™œìš©
        if 'YouTube_8M/YouTube_8M_video' in original_path:
            video_name = os.path.basename(original_path)  # video_XXX.mp4
            mapping_path = './videos/YouTube_8M/YouTube_8M_annotation/Movieclips_annotation.json'
            
            try:
                with open(mapping_path, 'r', encoding='utf-8') as f:
                    mapping_data = json.load(f)
                    video_info = next(
                        (item for item in mapping_data if item['video_name'] == video_name),
                        None
                    )
                    if video_info:
                        video_title = video_info['title']
                        print(f"\nğŸ¬ í´ë¦½ {i}: {video_title} (ID: {video_name})")
                    else:
                        print(f"\nğŸ¬ í´ë¦½ {i}: {video_name}")
            except Exception as e:
                print(f"\nğŸ¬ í´ë¦½ {i}: {video_name}")
        else:
            # ì™¸ë¶€ ì…ë ¥ ë¹„ë””ì˜¤ì˜ ê²½ìš° íŒŒì¼ëª…ë§Œ ì¶œë ¥
            video_name = os.path.basename(original_path)
            print(f"\nğŸ¬ í´ë¦½ {i}: {video_name}")
        
        print(f"â° êµ¬ê°„: {result['start_time']}ì´ˆ ~ {result['end_time']}ì´ˆ")
        print(f"ê²°ê³¼: {result['caption_ko']}")
        print("-" * 80)
    
    # ê²°ê³¼ ì¶œë ¥ í›„ ì‹œê°„ ê³„ì‚°
    total_time = time.time() - process_start_time
    minutes, seconds = divmod(total_time, 60)
    if minutes >= 60:
        hours, minutes = divmod(minutes, 60)
        print(f"\nâœ¨ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ (ì´ {int(hours)}ì‹œê°„ {int(minutes)}ë¶„ {seconds:.1f}ì´ˆ)")
    else:
        print(f"\nâœ¨ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ (ì´ {int(minutes)}ë¶„ {seconds:.1f}ì´ˆ)")
    
    print(f"ğŸ“Š ì²˜ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸: {len(results)}/{len(video_list)}")
    print(f"ğŸ’¾ í´ë¦½ ì €ì¥ ìœ„ì¹˜: {clips_dir}")

def text_to_video_search(query_text, new_videos_dir=None):
    """í…ìŠ¤íŠ¸ë¡œ ë¹„ë””ì˜¤ ê²€ìƒ‰í•˜ëŠ” íŒŒì´í”„ë¼ì¸"""
    print("\nğŸš€ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
    start_time = time.time()
    
    # ìƒˆë¡œìš´ ë¹„ë””ì˜¤ê°€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
    if new_videos_dir and os.path.exists(new_videos_dir):
        print(f"\nğŸ¥ ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘... ({new_videos_dir})")
    
        # ì„¤ì • ì—…ë°ì´íŠ¸
        SplitConfig.VIDEOS_DIR = new_videos_dir
        SplitConfig.SPLIT_VIDEOS_DIR = os.path.join(new_videos_dir, "split")
        
        # ë¶„ì‚° ì²˜ë¦¬ ì‹¤í–‰
        print("ğŸ“¦ ë¹„ë””ì˜¤ ë¶„í•  ë° ë¶„ì‚° ì²˜ë¦¬ ì‹œì‘...")
        process_start_time = time.time()
        split_process_main()
        
        # JSON ê²°ê³¼ ì·¨í•©
        print("\nğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ì·¨í•© ì¤‘...")
        json_results = []
        json_dir = "/data/ephemeral/home/json"  # ë©”ì¸ ì„œë²„ì˜ JSON ì €ì¥ ê²½ë¡œ
        
        for json_file in os.listdir(json_dir):
            if json_file.startswith("video_files_") and json_file.endswith(".json"):
                with open(os.path.join(json_dir, json_file), 'r') as f:
                    json_results.extend(json.load(f))
        
        # ìƒˆ ê²°ê³¼ë¥¼ DBì— ì¶”ê°€
        new_db_path = "output/text2video/new_videos_captions.json"
        with open(new_db_path, 'w', encoding='utf-8') as f:
            json.dump(json_results, f, indent=4, ensure_ascii=False)
        
        print(f"â±ï¸ ìƒˆ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ ({time.time() - process_start_time:.1f}ì´ˆ)")
    
    # FAISS ê²€ìƒ‰
    search_time = time.time()
    translator = DeepLTranslator()
    
    # DB ë¡œë“œ ë° í†µí•©
    main_db_path = "database/caption_embedding_tf.json"
    new_db_path = "output/text2video/new_videos_captions.json"

    combined_data = []
    with open(main_db_path, 'r', encoding='utf-8') as f:
        combined_data.extend(json.load(f))
    
    if os.path.exists(new_db_path):
        with open(new_db_path, 'r', encoding='utf-8') as f:
            combined_data.extend(json.load(f))
    
    temp_db_path = "output/text2video/temp_combined_db.json"
    with open(temp_db_path, 'w', encoding='utf-8') as f:
        json.dump(combined_data, f, indent=4, ensure_ascii=False)

    faiss_search = FaissSearch(json_path=temp_db_path)
    
    print(f"ğŸ” ê²€ìƒ‰ì–´: '{query_text}'")
    print(f"ğŸ” ê²€ìƒ‰ì–´ ë²ˆì—­: '{translator.translate_ko_to_en(query_text)}'")
    similar_captions = faiss_search.find_similar_captions(query_text, translator, top_k=2)
    print(f"â±ï¸ ê²€ìƒ‰ ì™„ë£Œ ({time.time() - search_time:.1f}ì´ˆ)")
    
    os.remove(temp_db_path)
    
    # ê²°ê³¼ ì¶œë ¥
    for i, (caption, similarity, video_info) in enumerate(similar_captions):
        print(f"\nğŸ¯ ê²€ìƒ‰ ê²°ê³¼ {i+1}")
        print(f"ğŸ“Š ìœ ì‚¬ë„: {similarity:.4f}")
        print(f"ğŸ¬ ë¹„ë””ì˜¤: {os.path.basename(video_info['video_path'])}")
        print(f"â° êµ¬ê°„: {video_info['start_time']}ì´ˆ ~ {video_info['end_time']}ì´ˆ")
        print(f"ğŸ“ ì œëª©: {video_info['title']}")
        print(f"ğŸ“ ìº¡ì…˜: {caption}")
    
    total_time = time.time() - start_time
    print(f"\nâœ¨ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ (ì´ {total_time:.1f}ì´ˆ)")

    return similar_captions

def main():
    parser = argparse.ArgumentParser(description='Video Processing Pipeline')
    parser.add_argument('mode', choices=['text2video', 'video2text'],
                      help='Choose pipeline mode: text2video or video2text')
    parser.add_argument('--new-videos', type=str, default=None,
                      help='Path to directory containing new videos to process')
    
    args = parser.parse_args()
    
    if args.mode == 'text2video':
        query_text = "ì´ˆë¡ìƒ‰ ì˜·ì„ ì…ê³ ìˆëŠ” ë‚¨ìê°€ ë©ˆì¶”ë¼ê³  í•˜ëŠ” ì¥ë©´" # ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ì¿¼ë¦¬ ì…ë ¥
        text_to_video_search(query_text, new_videos_dir=args.new_videos)
    else:
        video_to_text_process()

if __name__ == "__main__":
    main()