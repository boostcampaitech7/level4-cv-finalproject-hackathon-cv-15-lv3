import json
import csv
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.metrics.pairwise import cosine_similarity


def time_overlap(gt_start, gt_end, entry_start, entry_end):
    """ê²¹ì¹˜ëŠ” ì‹œê°„ ê³„ì‚°"""
    overlap_start = max(gt_start, entry_start)
    overlap_end = min(gt_end, entry_end)
    return max(0, overlap_end - overlap_start)  # ê²¹ì¹˜ëŠ” ì‹œê°„ì´ ì—†ìœ¼ë©´ 0

def load_criteria_from_excel(excel_path, db_data):
    """ì—‘ì…€ íŒŒì¼ì—ì„œ ê¸°ì¤€ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ DBì™€ ë§¤ì¹­"""
    print("ì—‘ì…€ íŒŒì¼ì—ì„œ ê¸°ì¤€ ë°ì´í„°ë¥¼ ë¡œë“œ ì¤‘...")
    
    try:
        df = pd.read_excel(excel_path)
    except Exception as e:
        print(f"ì—‘ì…€ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        exit(1)

    criteria_data = []
    unmatched_entries = 0

    print(f"ì´ {len(df)}ê°œì˜ ê¸°ì¤€ ë°ì´í„° í™•ì¸ ì™„ë£Œ. DBì—ì„œ ë§¤ì¹­ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    for _, row in tqdm(df.iterrows(), total=len(df), desc="ê¸°ì¤€ ë°ì´í„° ë§¤ì¹­ ì¤‘"):
        video_id = row['VideoURL']
        gt_start = row['StartTime']
        gt_end = row['EndTime']

        # DBì—ì„œ video_idì™€ urlì´ ì¼ì¹˜í•˜ëŠ” í•­ëª© ì°¾ê¸°
        matched_entries = [
            entry for entry in db_data
            if entry["video_id"] == video_id and entry["caption"] is not None
        ]

        if not matched_entries:
            unmatched_entries += 1
            continue  # ì¼ì¹˜í•˜ëŠ” í•­ëª©ì´ ì—†ëŠ” ê²½ìš° ìŠ¤í‚µ

        # start_time & end_timeì´ ê²¹ì¹˜ëŠ” ì •ë„ê°€ ê°€ì¥ í° í•­ëª© ì„ íƒ
        best_match = max(
            matched_entries,
            key=lambda e: time_overlap(gt_start, gt_end, float(e["start_time"]), float(e["end_time"]))
        )

        # QueryëŠ” ë”°ë¡œ ì €ì¥í•  í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì œê±°
        best_match.pop("query", None)

        # ìµœì¢… ê¸°ì¤€ ë°ì´í„°ì— ì¶”ê°€
        criteria_data.append(best_match)

    print(f"ê¸°ì¤€ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {len(criteria_data)}ê°œ í•­ëª© ì„ íƒ (ë§¤ì¹­ ì‹¤íŒ¨ {unmatched_entries}ê°œ ì œì™¸)")
    return criteria_data

def save_gt_db_as_json_and_csv(selected_data, json_output_path, csv_output_path):
    """GT-DBë¥¼ JSON ë° CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
    print(f"{len(selected_data)}ê°œì˜ ë°ì´í„° ì €ì¥ ì¤‘...")

    # JSON ì €ì¥
    with open(json_output_path, "w", encoding="utf-8") as json_file:
        json.dump(selected_data, json_file, ensure_ascii=False, indent=4)

    # CSV ì €ì¥
    with open(csv_output_path, "w", encoding="utf-8", newline="") as csv_file:
        fieldnames = ["video_path", "video_id", "video_title", "video_url", "start_time", "end_time", "caption"]
        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)
        writer.writeheader()
        for entry in selected_data:
            writer.writerow({
                "video_path": entry.get("video_path", ""),
                "video_id": entry.get("video_id", ""),
                "video_title": entry.get("video_title", ""),
                "video_url": entry.get("video_url", ""),
                "start_time": entry.get("start_time", ""),
                "end_time": entry.get("end_time", ""),
                "caption": entry.get("caption", "")
            })

    print(f"JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {json_output_path}")
    print(f"CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_output_path}")

def select_similar_data_based_on_criteria(criteria_data, db_data, embedding_key="embedding", top_k=6):
    """ê¸°ì¤€ì— ë”°ë¼ ìœ ì‚¬ë„ê°€ ë†’ì€ ë°ì´í„° ì„ íƒ"""
    print("ê¸°ì¤€ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ ì‚¬ë„ê°€ ë†’ì€ ë°ì´í„° ì°¾ê¸° ì‹œì‘...")

    selected_data = []
    
    for criterion in tqdm(criteria_data, desc="ìœ ì‚¬ë„ ê³„ì‚° ì¤‘"):
        if embedding_key not in criterion:
            print(f"ê²½ê³ : {criterion['video_id']}ì˜ ì„ë² ë”© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            continue

        criterion_embedding = np.array(criterion[embedding_key]).reshape(1, -1)
        similarities = []

        # ì „ì²´ DBì—ì„œ ìœ ì‚¬ë„ ê³„ì‚°
        for entry in db_data:
            if embedding_key not in entry or entry["caption"] is None:
                continue  

            entry_embedding = np.array(entry[embedding_key]).reshape(1, -1)
            similarity = cosine_similarity(criterion_embedding, entry_embedding)[0][0]
            similarities.append((similarity, entry))

        # ìœ ì‚¬ë„ê°€ ë†’ì€ í•­ëª© ì„ íƒ
        top_k_entries = sorted(similarities, key=lambda x: x[0], reverse=True)[:top_k]

        # ì„ íƒëœ í•­ëª© ì¶”ê°€
        for _, entry in top_k_entries:
            if "video_title" not in entry or "video_url" not in entry:
                print(f"ğŸš¨ ìœ ì‚¬ë„ ê¸°ë°˜ ì„ íƒëœ í•­ëª©ì—ì„œ video_title ë˜ëŠ” urlì´ ì—†ìŒ: {entry}")
            selected_entry = {
                "video_path": entry.get("video_path", ""),
                "video_id": entry.get("video_id", ""),
                "video_title": entry.get("video_title", ""),
                "video_url": entry.get("video_url", ""),
                "start_time": entry.get("start_time", ""),
                "end_time": entry.get("end_time", ""),
                "caption": entry.get("caption", "")
            }
            selected_data.append(selected_entry)

    print(f"ìœ ì‚¬ë„ ê¸°ë°˜ ìƒ˜í”Œë§ ì™„ë£Œ: {len(selected_data)}ê°œ í•­ëª© ì„ íƒë¨")
    return selected_data

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
excel_path = "/data/ephemeral/home/data/json_DB_v1/evaluation_dataset_v2.xlsx"
json_output_path = "gt_db_sampled_v1_tf.json"
csv_output_path = "gt_db_sampled_v1_tf.csv"

# ê¸°ì¤€ ë° DB ë°ì´í„° ë¡œë“œ
db_data_path = "/data/ephemeral/home/data/json_DB_v1/caption_embedding_tf.json"
print("DB ë°ì´í„° ë¡œë“œ ì¤‘...")
try:
    with open(db_data_path, "r", encoding="utf-8") as db_file:
        db_data = json.load(db_file)
    print(f"DB ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(db_data)}ê°œ í•­ëª©")
except Exception as e:
    print(f"DB ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit(1)

# ì—‘ì…€ì—ì„œ ê¸°ì¤€ ë°ì´í„° ì¶”ì¶œ
criteria_data = load_criteria_from_excel(excel_path, db_data)

# ë°ì´í„° ì„ íƒ ë° ì €ì¥
selected_data = select_similar_data_based_on_criteria(criteria_data, db_data)
save_gt_db_as_json_and_csv(selected_data, json_output_path, csv_output_path)