import json
import cohere
import numpy as np
import os
import time

# Cohere API í‚¤ ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
cohere_key = os.getenv("COHERE_API_KEY", "EmLgshjThMnpOpl14HlMpY4eiwWLhRLtxUxbws8x")  # API í‚¤ ì…ë ¥
co = cohere.Client(cohere_key)

# JSON íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
file_path = "../json/DB_v1.json"
with open(file_path, "r", encoding="utf-8") as f:
    data = json.load(f)

# caption ë‚´ìš© ì¶”ì¶œ
captions = [entry["caption"] for entry in data]

# ìµœì  ë°°ì¹˜ í¬ê¸° ì„¤ì • (ì•ˆì „í•œ ë²”ìœ„ì—ì„œ)
BATCH_SIZE = 100  # ì ì ˆí•œ ë°°ì¹˜ í¬ê¸°ë¡œ ì¦ê°€

# ê²°ê³¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
all_embeddings = []

# ì§„í–‰ë„ ì¶œë ¥ í•¨ìˆ˜
def print_progress(processed, total):
    progress = (processed / total) * 100
    print(f"\rProgress: [{processed}/{total}] {progress:.2f}%", end="", flush=True)

# ë°°ì¹˜ ì²˜ë¦¬
total_captions = len(captions)
for i in range(0, len(captions), BATCH_SIZE):
    batch = captions[i:i + BATCH_SIZE]
    try:
        result = co.embed(texts=batch, model="embed-english-v3.0", input_type="search_document")
        embeddings = np.asarray(result.embeddings)
        all_embeddings.extend(embeddings)
        time.sleep(5)  # API ì œí•œ ì´ˆê³¼ ë°©ì§€ë¥¼ ìœ„í•´ 3ì´ˆ ëŒ€ê¸°
    except cohere.errors.RateLimitError:
        print("\nğŸš¨ API Rate Limit Exceeded! 10ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
        time.sleep(10)  # API Rate Limit ì´ˆê³¼ ì‹œ 10ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
    
    # ì§„í–‰ë„ ì—…ë°ì´íŠ¸
    print_progress(len(all_embeddings), total_captions)

print("\nâœ… Embedding process completed!")

# JSONì— embedding ì¶”ê°€
for entry, embedding in zip(data, all_embeddings):
    entry["embedding"] = embedding.tolist()

# JSON ì €ì¥
output_file = "caption_embedding_voyage.json"
with open(output_file, "w", encoding="utf-8") as f:
    json.dump(data, f, ensure_ascii=False, indent=4)

print(f"âœ… Updated JSON saved to {output_file}")