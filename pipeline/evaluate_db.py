import pandas as pd
import json
import os
from text_to_video.embedding import FaissSearch
from utils.translator import DeepGoogleTranslator

def evaluate_search_performance(excel_path, db_path, top_k=5):
    """ê²€ìƒ‰ ì„±ëŠ¥ í‰ê°€"""
    # Excel íŒŒì¼ ì½ê¸°
    df = pd.read_excel(excel_path)
    
    # FAISS ê²€ìƒ‰ ì´ˆê¸°í™”
    translator = DeepGoogleTranslator()
    faiss_search = FaissSearch(json_path=db_path)
    
    # í‰ê°€ ì§€í‘œ
    metrics = {
        'total_queries': len(df),
        'found_in_topk': 0,
        'mean_rank': 0,
        'mean_similarity': 0,
        'detailed_results': []
    }
    
    print(f"\nğŸ“Š ê²€ìƒ‰ ì„±ëŠ¥ í‰ê°€ ì‹œì‘ (top-{top_k})")
    
    for _, row in df.iterrows():
        query = row['Query']
        video_id = row['VideoURL'].split('=')[-1]
        gt_start = row['StartTime']
        gt_end = row['EndTime']
        
        # ì¿¼ë¦¬ ë²ˆì—­
        query_en = translator.translate_ko_to_en(query)
        print(f"\nğŸ” ì¿¼ë¦¬ í‰ê°€ ì¤‘:")
        print(f"   ì›ë³¸: {query}")
        print(f"   ë²ˆì—­: {query_en}")
        
        # ì „ì²´ DBì—ì„œ ê²€ìƒ‰
        results = faiss_search.find_similar_captions(query, translator, top_k=top_k)
        
        # ê²°ê³¼ ë¶„ì„
        found = False
        rank = -1
        max_similarity = 0
        
        for i, (caption_ko, similarity, video_info) in enumerate(results, 1):
            # video_pathì—ì„œ video_id ì¶”ì¶œ
            result_video_id = video_info.get('video_id')
            start_time = float(video_info['start_time'])
            end_time = float(video_info['end_time'])
            
            # ì •ë‹µ ë¹„ë””ì˜¤ì´ê³  ì‹œê°„ì´ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸
            if result_video_id == video_id:
                time_overlap = (
                    (start_time <= gt_start <= end_time) or
                    (start_time <= gt_end <= end_time) or
                    (gt_start <= start_time <= gt_end)
                )
                if time_overlap:
                    found = True
                    rank = i
                    max_similarity = similarity
                    break
        
        # ê²°ê³¼ ì €ì¥ - similarityë¥¼ floatë¡œ ë³€í™˜
        result_info = {
            'query': query,
            'video_id': video_id,
            'found': found,
            'rank': rank,
            'similarity': float(max_similarity),  # float32ë¥¼ floatë¡œ ë³€í™˜
            'gt_start': float(gt_start),         # í˜¹ì‹œ ëª¨ë¥¼ ë‹¤ë¥¸ float32 ê°’ë“¤ë„ ë³€í™˜
            'gt_end': float(gt_end)
        }
        metrics['detailed_results'].append(result_info)
        
        # í†µê³„ ì—…ë°ì´íŠ¸ - similarityë¥¼ floatë¡œ ë³€í™˜
        if found:
            metrics['found_in_topk'] += 1
            metrics['mean_rank'] += rank
            metrics['mean_similarity'] += float(max_similarity)
        
        # ê²°ê³¼ ì¶œë ¥
        status = "âœ… ë°œê²¬" if found else "âŒ ë¯¸ë°œê²¬"
        print(f"{status} (ìˆœìœ„: {rank if found else 'N/A'}, ìœ ì‚¬ë„: {max_similarity:.4f})")
    
    # ìµœì¢… í†µê³„ ê³„ì‚° - ê²°ê³¼ë¥¼ floatë¡œ ë³€í™˜
    if metrics['found_in_topk'] > 0:
        metrics['mean_rank'] = float(metrics['mean_rank'] / metrics['found_in_topk'])
        metrics['mean_similarity'] = float(metrics['mean_similarity'] / metrics['found_in_topk'])
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼:")
    print(f"ì´ ì¿¼ë¦¬ ìˆ˜: {metrics['total_queries']}")
    print(f"Top-{top_k} ë‚´ ë°œê²¬: {metrics['found_in_topk']} ({metrics['found_in_topk']/metrics['total_queries']*100:.1f}%)")
    if metrics['found_in_topk'] > 0:
        print(f"í‰ê·  ìˆœìœ„: {metrics['mean_rank']:.2f}")
        print(f"í‰ê·  ìœ ì‚¬ë„: {metrics['mean_similarity']:.4f}")
    
    # ê²°ê³¼ ì €ì¥
    output_dir = "results/search_evaluation"
    os.makedirs(output_dir, exist_ok=True)
    
    output_path = os.path.join(output_dir, f"search_evaluation_top{top_k}.json")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(metrics, f, ensure_ascii=False, indent=4)
    
    print(f"\nâœ… í‰ê°€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
    return metrics

def main():
    excel_path = "csv/evaluation_dataset_v2.xlsx"
    db_configs = [
        "output/text2video/test2_db_d5_t2v_captions.json",
        "output/text2video/test2_db_s_t2v_captions.json",
        "output/text2video/test2_db_pya_t2v_captions.json",
        "output/text2video/test2_db_pyc_t2v_captions.json"
    ]
    
    for db_path in db_configs:
        print(f"\nğŸ¯ DB í‰ê°€ ì¤‘: {db_path}")
        evaluate_search_performance(excel_path, db_path, top_k=10)

if __name__ == "__main__":
    main()