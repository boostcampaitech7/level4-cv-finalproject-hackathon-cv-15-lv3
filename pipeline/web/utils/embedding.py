import faiss
import json
import os
import time
import numpy as np
import requests
from sentence_transformers import SentenceTransformer

class FaissSearch:
    """FAISS ê¸°ë°˜ ê²€ìƒ‰ ì‹œìŠ¤í…œ í´ë˜ìŠ¤"""

    def __init__(self, json_path, model_name="all-MiniLM-L6-v2", use_gpu=True):
        self.json_path = json_path
        self.model = SentenceTransformer(model_name)

        # âœ… JSON ë°ì´í„° ë¡œë“œ ë˜ëŠ” ìƒì„±
        start_time = time.time()
        if os.path.exists(self.json_path):
            self._load_json_data()
        else:
            print("ğŸ“‚ JSON íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ìƒˆë¡œìš´ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤...")
            self.generate_and_save_embeddings("output/captions.json")
            self._load_json_data()
        print(f"ğŸ•’ JSON ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {time.time() - start_time:.4f} ì´ˆ")

        # âœ… FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™”
        start_time = time.time()
        self._initialize_faiss(use_gpu)
        print(f"ğŸ•’ FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ: {time.time() - start_time:.4f} ì´ˆ")

    def _load_json_data(self):
        """JSON íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ìº¡ì…˜ ë° ì„ë² ë”©ì„ ê°€ì ¸ì˜´"""
        start_time = time.time()
        with open(self.json_path, "r", encoding="utf-8") as f:
            self.data = json.load(f)
        self.captions = [entry["caption"] for entry in self.data]
        self.embeddings = np.array([entry["embedding"] for entry in self.data], dtype=np.float32)
        faiss.normalize_L2(self.embeddings)
        print(f"ğŸ•’ JSON ë¡œë“œ ë° ë°ì´í„° ì •ê·œí™” ì™„ë£Œ: {time.time() - start_time:.4f} ì´ˆ")

    def _initialize_faiss(self, use_gpu):
        """FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„± ë° ì´ˆê¸°í™”"""
        start_time = time.time()
        self.dimension = self.embeddings.shape[1]
        self.res = faiss.StandardGpuResources() if use_gpu else None
        self.index = faiss.IndexFlatIP(self.dimension)
        self.gpu_index = faiss.index_cpu_to_gpu(self.res, 0, self.index) if use_gpu else self.index
        self.gpu_index.add(self.embeddings)
        print(f"ğŸ•’ FAISS ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {time.time() - start_time:.4f} ì´ˆ")

    def generate_and_save_embeddings(self, source_json_path):
        """ìƒˆë¡œìš´ ì„ë² ë”©ì„ ìƒì„±í•˜ì—¬ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if not os.path.exists(source_json_path):
            print(f"ğŸš¨ ì˜¤ë¥˜: {source_json_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return

        print("ğŸ”„ ìº¡ì…˜ì„ ì„ë² ë”©í•˜ê³  JSONì— ì €ì¥ ì¤‘...")
        start_time = time.time()

        with open(source_json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        encode_start_time = time.time()
        for entry in data:
            caption_text = entry["caption"]
            embedding = self.model.encode(caption_text).tolist()  # NumPy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            entry["embedding"] = embedding
        print(f"ğŸ•’ ëª¨ë“  ìº¡ì…˜ ì„ë² ë”© ì™„ë£Œ: {time.time() - encode_start_time:.4f} ì´ˆ")

        save_start_time = time.time()
        with open(self.json_path, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
        print(f"ğŸ•’ JSON ì €ì¥ ì™„ë£Œ: {time.time() - save_start_time:.4f} ì´ˆ")

        print(f"âœ… ìƒˆë¡œìš´ ì„ë² ë”© ì €ì¥ ì™„ë£Œ! â†’ {self.json_path}")
        print(f"ğŸ•’ ì „ì²´ ì„ë² ë”© ì²˜ë¦¬ ì™„ë£Œ: {time.time() - start_time:.4f} ì´ˆ")

    def find_similar_captions(self, input_text, translator, top_k=3):

        """í•œêµ­ì–´ ì…ë ¥ â†’ ì˜ì–´ ë³€í™˜ â†’ FAISS ê²€ìƒ‰ â†’ í•œêµ­ì–´ ë³€í™˜ í›„ ê²°ê³¼ ë°˜í™˜ (ë³‘ë ¬ ë²ˆì—­ ìµœì í™”)"""
        # âœ… Step 1: ì…ë ¥ í…ìŠ¤íŠ¸ ë²ˆì—­
        start_time = time.time()
        
        if hasattr(translator, "batch_translate"):
            translated_query = translator.batch_translate([input_text], direction="ko_to_en")[0]
        else:
            translated_query = translator.translate_ko_to_en(input_text)

        print(f"ğŸ•’ ë²ˆì—­ (KOâ†’EN) ì™„ë£Œ: {time.time() - start_time:.4f} ì´ˆ")

        if not translated_query:
            print("ğŸš¨ ë²ˆì—­ ì‹¤íŒ¨! ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return []

        # âœ… Step 2: ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        start_time = time.time()
        query_embedding = self.model.encode([translated_query]).astype(np.float32)
        faiss.normalize_L2(query_embedding)
        print(f"ğŸ•’ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì™„ë£Œ: {time.time() - start_time:.4f} ì´ˆ")

        # âœ… Step 3: FAISS ê²€ìƒ‰
        start_time = time.time()
        D, I = self.gpu_index.search(query_embedding, top_k)
        print(f"ğŸ•’ FAISS ê²€ìƒ‰ ì™„ë£Œ: {time.time() - start_time:.4f} ì´ˆ")

        # âœ… Step 4: ê²€ìƒ‰ ê²°ê³¼ ë²ˆì—­ (EN â†’ KO) ë³‘ë ¬ ìµœì í™”
        start_time = time.time()
        
        captions_en = [self.captions[i] for i in I[0]]
        
        if hasattr(translator, "batch_translate"):
            captions_ko = translator.batch_translate(captions_en, direction="en_to_ko")
        else:
            captions_ko = [translator.translate_en_to_ko(caption) for caption in captions_en]

        results = []
        for idx, i in enumerate(I[0]):
            video_info = {
                'video_path': self.data[i]['video_path'],
                'video_id': self.data[i]['video_id'],
                'clip_id': self.data[i]['clip_id'],
                'start_time': self.data[i]['start_time'],
                'end_time': self.data[i]['end_time']
            }
            results.append((captions_ko[idx], D[0][idx], video_info))

        print(f"ğŸ•’ ê²€ìƒ‰ ê²°ê³¼ ë²ˆì—­ ì™„ë£Œ: {time.time() - start_time:.4f} ì´ˆ")
        
        return results